{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Detect Duplicates Using Hashing\n",
    "\n",
    "This is a high level introduction into hashing, and then how to detect duplicate objects through hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binascii import hexlify\n",
    "from base64 import urlsafe_b64encode\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "from hmac import compare_digest\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import uuid\n",
    "\n",
    "import requests as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Introduction\n",
    "\n",
    "### What is a hash?\n",
    "\n",
    "A hash function is a deterministic mathematical function that takes an input of any length and content (e.g. letters, numbers, and symbols) and uses a formula to produce an output of a specific length.\n",
    "\n",
    "A hash function differs from an encryption algorithm in that hash functions are not reversible whereas encryption algorithms are reversible.  \n",
    "\n",
    "### What can be hashed?\n",
    "\n",
    "A hash can be created using nearly any form of digitial content: a document, image, song, etc.\n",
    "\n",
    "\n",
    "references: \n",
    "* [What is hashing?](https://medium.com/tech-tales/what-is-hashing-6edba0ebfa67)\n",
    "* [About Secure Password Hashing](https://security.blogoverflow.com/2013/09/about-secure-password-hashing/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the hasher\n",
    "hasher = hashlib.sha256()\n",
    "\n",
    "# let's hash something\n",
    "hasher.update(b\"I am a fun hash!\")\n",
    "\n",
    "print(\"I am a fun hash!: \" + hasher.hexdigest())\n",
    "\n",
    "hasher.update(b\"To be or not to be\")\n",
    "\n",
    "print(\"I am a fun hash!  To be or not to be: \" + hasher.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD5 (Messsage Digest) Hashing Examples\n",
    "\n",
    "hasher = hashlib.md5()\n",
    "\n",
    "shakespeare_sonnet = \"\"\"\n",
    "Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the darling buds of May,\n",
    "And summer’s lease hath all too short a date;\n",
    "Sometime too hot the eye of heaven shines,\n",
    "And often is his gold complexion dimm'd;\n",
    "And every fair from fair sometime declines,\n",
    "By chance or nature’s changing course untrimm'd;\n",
    "But thy eternal summer shall not fade,\n",
    "Nor lose possession of that fair thou ow’st;\n",
    "Nor shall death brag thou wander’st in his shade,\n",
    "When in eternal lines to time thou grow’st:\n",
    "So long as men can breathe or eyes can see,\n",
    "So long lives this, and this gives life to thee.\n",
    "\"\"\"\n",
    "\n",
    "hasher.update(shakespeare_sonnet.encode('utf-8'))\n",
    "\n",
    "print(hasher.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing an image\n",
    "\n",
    "paris_picture = 'https://lonelyplanetimages.imgix.net/mastheads/GettyImages-500759045_super.jpg?sharp=10&vib=20&w=1200'\n",
    "\n",
    "image_binary = r.get(paris_picture).content\n",
    "\n",
    "print('Image size: ' + str(len(image_binary)))\n",
    "\n",
    "print(b'some of the image content:' + image_binary[0:10])\n",
    "\n",
    "picture_hash = hashlib.md5(image_binary)\n",
    "\n",
    "print('Image hash: ' + picture_hash.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing a large amount of data\n",
    "# This is not cryptographically secure\n",
    "\n",
    "def string_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "random_str_1 = string_generator(size=10**2)\n",
    "\n",
    "md5_hash_rand_str_1 = hashlib.md5(random_str_1.encode())\n",
    "sha256_hash_rand_str_1 = hashlib.sha256(random_str_1.encode())\n",
    "sha512_hash_rand_str_1 = hashlib.sha512(random_str_1.encode())\n",
    "\n",
    "print('MD5: ' + md5_hash_rand_str_1.hexdigest())\n",
    "print('SHA-256: ' + sha256_hash_rand_str_1.hexdigest())\n",
    "print('SHA-512: ' + sha512_hash_rand_str_1.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_str_2 = string_generator(size=10**5)\n",
    "\n",
    "md5_hash_rand_str_2 = hashlib.md5(random_str_2.encode())\n",
    "sha256_hash_rand_str_2 = hashlib.sha256(random_str_2.encode())\n",
    "sha512_hash_rand_str_2 = hashlib.sha512(random_str_2.encode())\n",
    "\n",
    "print('MD5: ' + md5_hash_rand_str_2.hexdigest())\n",
    "print('SHA-256: ' + sha256_hash_rand_str_2.hexdigest())\n",
    "print('SHA-512: ' + sha512_hash_rand_str_2.hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:  How to detect duplicate dictionaries\n",
    "\n",
    "Suppose Alice sends Bob a series of JSON objects over the wire, but Alice is forgetful and sends Bob multiple JSON blobs containing the same data.  Bob doesn't want to have to read Alice's messages multiple times, so he needs a way to figure out if they're duplicate messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alices_messages = [\n",
    "    {'message': 'Hello, Bob!', 'timestamp': datetime.now()},\n",
    "    {'message': 'How are you doing, Bob?', 'timestamp': datetime.now()},\n",
    "    {'id': 12454432, 'message': 'I see you Bob!', 'timestamp': datetime.now()},\n",
    "    {'message': 'How are you doing, Bob?', 'timestamp': datetime.now()},\n",
    "]\n",
    "\n",
    "print(alices_messages)\n",
    "\n",
    "\n",
    "# bob gets the message batch\n",
    "\n",
    "for message in alices_messages:\n",
    "    encoded_message = message.get('message').encode('utf-8')\n",
    "    message_hash = hashlib.sha256(encoded_message).hexdigest()\n",
    "    print(f'{encoded_message}: {message_hash}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bob notices Alice is sending duplicate messages, and decides to create a dictionary to filter them.\n",
    "duplicate_timestamp = datetime.now()\n",
    "\n",
    "alices_messages = [\n",
    "    {'message': 'Hello, Bob!', 'timestamp': datetime.now(), 'weather': 'cloudy with a chance of meatballs'},\n",
    "    {'message': 'How are you doing, Bob?', 'timestamp': duplicate_timestamp},\n",
    "    {'id': 12454432, 'message': 'I see you Bob!', 'timestamp': datetime.now()},\n",
    "    {'message': 'How are you doing, Bob?', 'timestamp': duplicate_timestamp},\n",
    "]\n",
    "\n",
    "unique_messages = {}\n",
    "\n",
    "for message in alices_messages:\n",
    "    encoded_message = json.dumps(message, sort_keys=True, default=str)\n",
    "    print(f'encoded message: {encoded_message}')\n",
    "    message_hash = hashlib.sha256(encoded_message.encode('utf-8')).hexdigest()\n",
    "    print(f'hash: {message_hash}')\n",
    "    \n",
    "    # check to see if message exists, and if not add it to the docket\n",
    "    if message_hash not in unique_messages:\n",
    "        unique_messages.update({message_hash: message})\n",
    "    else:\n",
    "        print('Silly Alice, she sent a duplicate message!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cryptographically Secure Hashing\n",
    "\n",
    "### Overview\n",
    "\n",
    "The primary difference between encryption and hashing is that encryption is reversible; however, hashing is not reversible.\n",
    "\n",
    "A hashing functions is a _cryptographic hash functions_ when it has the following properties:\n",
    "   \n",
    "   * It is easy to compute the hash value for any given input.\n",
    "   * It is infeasible to generate the given input from a given hash.\n",
    "   * If is infeasible to modify the input without modifying the hash.\n",
    "   * It is infeasible for two different inputs to produce the same hash.\n",
    "   \n",
    "The hash functions should be resistant against:\n",
    "\n",
    "   * Collisions\n",
    "   * Pre-image resistance - Given a hash h it should be difficult to find any input m such that h = hash(m)\n",
    "   * Second-preimages - given m, it is infeasible to find m' distinct from m such that hash(m) = hash(m')\n",
    "   \n",
    "### Modern Hashing Algorithms\n",
    "\n",
    "    * MD-5 is a hashing algorithm that is widely used, but is cryptographically flawed because it is prone to collisions.  MD-5 is broken in terms of collisions, but still is resistant in terms of pre-images and secod-preimages.\n",
    "    * SHA-256/SHA-512 are hashing functions that are similar, but work on different block sizes.  These were designed by the NSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a key\n",
    "KEY_LENGTH = 30\n",
    "AUTH_SIZE = 16\n",
    "\n",
    "secret_key = hexlify(os.urandom(KEY_LENGTH))\n",
    "\n",
    "\n",
    "def sign(cookie):\n",
    "    h = hashlib.blake2b(digest_size=AUTH_SIZE, key=secret_key)\n",
    "    h.update(cookie.encode('utf-8'))\n",
    "    return h.hexdigest().encode('utf-8')\n",
    "\n",
    "\n",
    "def verify(cookie, sig):\n",
    "    good_sig = sign(cookie)\n",
    "    return compare_digest(good_sig, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie = {'user': 'alice', 'auth_mode': 'token'}\n",
    "cookie_str = json.dumps(cookie, sort_keys=True)\n",
    "sig = sign(cookie_str)\n",
    "\n",
    "print(cookie_str)\n",
    "print(sig)\n",
    "\n",
    "print(verify(cookie_str, sig))\n",
    "\n",
    "invalid_cookie = {'user': 'admin', 'auth_mode': 'token'}\n",
    "invalid_cookie_str = json.dumps(invalid_cookie, sort_keys=True)\n",
    "print(sign(invalid_cookie_str))\n",
    "\n",
    "print(verify(invalid_cookie_str, sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a random password and hashing.\n",
    "# Note: Don't actually use this in a system. It is far better to use a package written by an expert.\n",
    "\n",
    "password = 'spam_me_password'\n",
    "salt = urlsafe_b64encode(uuid.uuid4().bytes)\n",
    "\n",
    "print('Salt: ' + salt.decode())\n",
    "\n",
    "hasher = hashlib.sha512()\n",
    "hasher.update(password.encode() + salt)\n",
    "hashed_password = urlsafe_b64encode(hasher.digest())\n",
    "\n",
    "print('Hashed password:' + hashed_password.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Duplicate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def hash_file(file_path, block_size=1024):\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        hasher.update(f.read(block_size))\n",
    "    return hasher.hexdigest().encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate some random files in a temp directory.\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "print('Temporary Directory: ' + temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(os.path.join(temp_dir, 'f.txt'), 'wb')\n",
    "f.write(os.urandom(2048))\n",
    "f.close()\n",
    "\n",
    "g = open(os.path.join(temp_dir, 'g.txt'), 'wb')\n",
    "g.write(os.urandom(2048**2))\n",
    "g.close()\n",
    "\n",
    "f_hash = hash_file(os.path.join(temp_dir, 'f.txt'))\n",
    "print('f.txt hash: ' + f_hash.decode())\n",
    "\n",
    "g_hash = hash_file(os.path.join(temp_dir, 'g.txt'))\n",
    "print('g.txt hash: ' + g_hash.decode())\n",
    "\n",
    "compare_digest(f_hash, g_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate random files.\n",
    "FILE_NUM = 1000\n",
    "DUP_FILE_NUM = 10\n",
    "\n",
    "random_data = (os.urandom(2048) for _ in range(0, FILE_NUM))\n",
    "for indx, random_datum in enumerate(random_data):\n",
    "    with open(os.path.join(temp_dir, '{}.txt'.format(str(indx))), 'wb') as f:\n",
    "        f.write(random_datum)\n",
    "\n",
    "# generate 1 duplicate file\n",
    "random_files = [os.path.join(temp_dir, '{}.txt'.format(str(random.randint(0, FILE_NUM - 1)))) for _ in range(DUP_FILE_NUM)]\n",
    "\n",
    "for random_file in random_files:\n",
    "    with open(random_file, 'rb') as f:\n",
    "        dup_file = os.path.basename(random_file)\n",
    "        with open(os.path.join(temp_dir, 'dup_file_{}.txt'.format(dup_file)), 'wb') as g:\n",
    "            g.write(f.read())\n",
    "        \n",
    "print(random_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and list duplicate files.\n",
    "# Algorithm is ~ O(n^2)\n",
    "\n",
    "# Iterate over files in temp_dir\n",
    "for root, directory, files in os.walk(temp_dir):\n",
    "    # pick a file and iterate over it\n",
    "    for o_file in files:\n",
    "        o_fp = os.path.join(root, o_file)\n",
    "        # print('checking: {}'.format(o_fp))\n",
    "        outer_hash = hash_file(o_fp)\n",
    "        for i_file in files:\n",
    "            if o_file != i_file:\n",
    "                i_fp = os.path.join(root, i_file)\n",
    "                inner_hash = hash_file(i_fp)\n",
    "                if compare_digest(outer_hash, inner_hash):\n",
    "                    print('  found duplicate files: {} and {}'.format(o_fp, i_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temp_dir\n",
    "\n",
    "shutil.rmtree(temp_dir)\n",
    "\n",
    "os.path.exists(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashable Objects\n",
    "\n",
    "The builtin method `hash()` returns the hash value of an object if it has one, and returns an integer value.  This is used to quickly find dictionary keys during a dictionary lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hash('Spam!'))\n",
    "\n",
    "print(hash('I am a comnputer?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuples have a hash value\n",
    "hash((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists don't have a hash value\n",
    "hash([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alpaca:\n",
    "    \n",
    "    def __init__(self, name, color):\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.color == other.color\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.color))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Alpaca({}, {})'.format(self.name, self.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_1 = Alpaca('Bob', 'purple')\n",
    "alpaca_2 = Alpaca('Erin', 'blue')\n",
    "\n",
    "print(hash(alpaca_1))\n",
    "print(hash(alpaca_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_farm = {}\n",
    "alpaca_farm.update({alpaca_1: alpaca_1})\n",
    "alpaca_farm.update({alpaca_2: alpaca_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alpaca = Alpaca('Bob', 'purple')\n",
    "child_alpaca = Alpaca('Anna', 'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alpaca in alpaca_farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_alpaca in alpaca_farm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
